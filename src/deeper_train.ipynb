{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "from load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', \n",
    "                4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "X_all, Y_all = load_data('../data/fer2013.csv')\n",
    "assert len(X_all) == len(Y_all)\n",
    "\n",
    "# save 20% for testing\n",
    "test_start = int(.80 * len(X_all))\n",
    "X_train, Y_train = X_all[:test_start, :], Y_all[:test_start, :]\n",
    "X_test, Y_test = X_all[test_start:, :], Y_all[test_start:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001\n",
    "epochs = 70\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#INPUT\n",
    "input = tf.placeholder(dtype=tf.float32, shape=[None, 2304], name='Input')\n",
    "input_shaped = tf.reshape(input, [-1, 48, 48, 1])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 7], name='Output')\n",
    "\n",
    "#  ARCHITECTURE\n",
    "layer1 = tf.layers.conv2d(input_shaped, filters=64, kernel_size=[5, 5],  padding='same', activation=tf.nn.relu, name='l1_conv2d')\n",
    "layer1 = tf.layers.max_pooling2d(layer1, pool_size=[2, 2], strides=2, name='l1_maxpool')\n",
    "layer1 = tf.layers.dropout(layer1, rate=0.5, name='l1_dropout')\n",
    "\n",
    "layer2 = tf.layers.conv2d(layer1, filters=64, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, name='l2_conv2d')\n",
    "layer2 = tf.layers.max_pooling2d(layer2, pool_size=[2, 2], strides=2, name='l2_maxpool')\n",
    "layer2 = tf.layers.dropout(layer2, rate=0.5, name='l2_dropout')\n",
    "\n",
    "layer3 = tf.layers.conv2d(layer2, filters=64, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, name='l3_conv2d')\n",
    "layer3 = tf.layers.max_pooling2d(layer3, pool_size=[2, 2], strides=2, name='l3_maxpool')\n",
    "layer3 = tf.layers.dropout(layer1, rate=0.5, name='l3_dropout')\n",
    "\n",
    "layer4 = tf.layers.conv2d(layer3, filters=128, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, name='l4_conv2d')\n",
    "layer4 = tf.layers.max_pooling2d(layer4, pool_size=[2, 2], strides=2, name='l4_maxpool')\n",
    "layer4 = tf.layers.dropout(layer4, rate=0.5, name='l4_dropout')\n",
    "\n",
    "layer5 = tf.layers.conv2d(layer4, filters=128, kernel_size=[5, 5], padding='same', activation=tf.nn.relu, name='l5_conv2d')\n",
    "layer5 = tf.layers.max_pooling2d(layer5, pool_size=[2, 2], strides=2, name='l5_maxpool')\n",
    "layer5 = tf.layers.dropout(layer5, rate=0.5, name='l5_dropout')\n",
    "\n",
    "\n",
    "flattened = tf.reshape(layer5, [-1, 6 * 6 * 128], name='flattened')\n",
    "dense1024 = tf.layers.dense(flattened, units=1024, activation=tf.nn.relu, name='l6_dense_1024')\n",
    "dropout = tf.layers.dropout(dense1024, rate=0.5, name='l6_dropout')\n",
    "dense512 = tf.layers.dense(dropout, units=512, activation=tf.nn.relu, name='l7_dense_512')\n",
    "dropout2 = tf.layers.dropout(dense512, rate=0.5, name='l7_dropout2')\n",
    "logits = tf.layers.dense(dropout2, units=7, name='l8_dense_7')\n",
    "\n",
    "probs = tf.nn.softmax(logits, name='y_softmax')\n",
    "y_predict = tf.argmax(probs, axis=1, name='y_predict')\n",
    "y_true = tf.argmax(y, axis=1, name='y_true')\n",
    "\n",
    "entropy_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=alpha).minimize(entropy_cost)\n",
    "correct_prediction = tf.equal(y_true, y_predict)\n",
    "accurary = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "logging_steps = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    writer = tf.summary.FileWriter('./../graphs', sess.graph)\n",
    "\n",
    "    n_batches = int(len(X_train) / batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            idx = i * batch_size\n",
    "            batch_x = X_train[idx: idx + batch_size]\n",
    "            batch_y = Y_train[idx: idx + batch_size]\n",
    "            _, result = sess.run([optimiser, entropy_cost], feed_dict={input: batch_x, y: batch_y})\n",
    "            avg_cost += result / n_batches\n",
    "\n",
    "        test_accuracy = sess.run(accurary, feed_dict={input: X_test, y: Y_test})\n",
    "        \n",
    "        if epoch % logging_steps == 0:\n",
    "            print('\\nEpoch:' + str(epoch + 1) + ' cost = {:.3f}'.format(avg_cost) + ' test accuracy: {:.3f}'.format(test_accuracy))\n",
    "            file.write('\\nEpoch:' + str(epoch + 1) + ' cost = {:.3f}'.format(avg_cost) + ' test accuracy: {:.3f}'.format(test_accuracy))\n",
    "\n",
    "    print('\\nTraining Complete')\n",
    "    print('\\naccurary: {0}\\n'.format(sess.run(accurary, feed_dict={input: X_test, y: Y_test})))\n",
    "    file.close()\n",
    "    saver.save(sess, 'model-dropout-deeper')\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
